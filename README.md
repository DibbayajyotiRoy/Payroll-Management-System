# Rust Payroll System API

[![Rust Version](https://img.shields.io/badge/rust-1.79.0-orange.svg)](https://www.rust-lang.org/)

A high-performance, next-generation payroll management system built with Rust, Actix-web, and PostgreSQL. It's designed to be a robust backend supporting cutting-edge features like AI-powered analytics, real-time payroll processing, blockchain integration, and advanced employee self-service.

## Features

- **High Performance:** Built with Rust and the Actix-web framework for speed and safety.
- **Asynchronous:** Fully async from the web layer down to the database.
- **Modern Database:** Uses PostgreSQL with `Diesel` for safe and efficient database interactions.
- **Advanced Data Models:** Supports complex JSON-based data structures for analytics, benefits, and more.
- **Ready for the Future:** Designed to integrate AI, blockchain, and real-time payment features.
- **Multi-Component Architecture:** Separate binaries for the web server, background worker, and scheduler for better separation of concerns and scalability.

## Architecture

The system is composed of three main components that run as separate processes:

- **Web Server (`basics`):** The main entry point for all API requests. It handles HTTP requests, validation, and calls the appropriate services.
- **Background Worker (`worker`):** Responsible for processing long-running, asynchronous tasks such as sending emails, generating reports, or processing payroll batches.
- **Scheduler (`scheduler`):** Manages and triggers scheduled tasks, such as running payroll on a specific date or generating monthly reports.

This separation allows for independent scaling and development of each component.

## Getting Started

### Prerequisites

- [Rust](https://www.rust-lang.org/tools/install) (latest stable version)
- [PostgreSQL](https://www.postgresql.org/download/)
- [Diesel CLI](https://diesel.rs/guides/getting-started) (`cargo install diesel_cli --no-default-features --features postgres`)
- [cargo-make](https://github.com/sagiegurari/cargo-make) (`cargo install cargo-make`)

### Installation & Running

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd <your-repo-folder>
    ```

2.  **Set up the environment:**
    Create a `.env` file in the project root and add your database URL:
    ```.env
    DATABASE_URL="postgres://user:password@localhost/your_db_name"
    ```

3.  **Run database migrations:**
    This will create and update your database tables to match the application's models.
    ```bash
    diesel migration run
    ```

4.  **Build and run the application:**
    The easiest way to get everything running for development is to use the `start-all` task, which will build and run the web server, worker, and scheduler in parallel.

    ```bash
    cargo make start-all
    ```

    The server will start on `http://127.0.0.1:8080`.

## Usage

This project uses `cargo-make` as a task runner to simplify common development tasks. The tasks are defined in the `Makefile.toml` file.

-   **`cargo make start-all`**: Builds and runs the web server, worker, and scheduler in parallel.
-   **`cargo make build-all`**: Compiles all binaries.
-   **`cargo make run-web`**: Runs the main web server binary.
-   **`cargo make run-worker`**: Runs the background worker binary.
-   **`cargo make run-scheduler`**: Runs the scheduler binary.

## API Documentation

The API is documented using the OpenAPI standard. You can access the interactive API documentation in two ways:

1.  **While the server is running:** Navigate to [http://127.0.0.1:8080/docs](http://127.0.0.1:8080/docs) in your browser.
2.  **Offline:** Open the `api-docs/scalar.html` or `api-docs/swagger.html` files directly in your browser.

The documentation provides a list of all available endpoints, their parameters, and response objects. You can also use the interactive interface to send test requests to the API.

## Testing

To run the test suite, use the following command:

```bash
cargo test
```

## Project Structure

```
.
├── api-docs/           # OpenAPI and Swagger documentation files
├── migrations/         # Diesel database migrations
├── src/
│   ├── api/            # API specific types and data structures
│   ├── bin/            # Entry points for the worker and scheduler binaries
│   ├── calculation/    # Business logic for payroll calculations
│   ├── config/         # Application configuration
│   ├── domain/         # Core domain models and error types
│   ├── services/       # Business logic services (e.g., PayrollService)
│   ├── web/            # Web handlers and routes
│   ├── db.rs           # Database connection setup
│   ├── lib.rs          # Library crate root
│   ├── main.rs         # Main web server entry point
│   └── schema.rs       # Auto-generated by Diesel
├── tests/              # Integration and unit tests
├── .env                # Environment variables (needs to be created)
├── Cargo.toml          # Project dependencies and metadata
└── Makefile.toml       # Task definitions for cargo-make
```
# Rust Payroll System API

[![Rust Version](https://img.shields.io/badge/rust-1.79.0-orange.svg)](https://www.rust-lang.org/)

A high-performance, next-generation payroll management system built with Rust, Actix-web, and PostgreSQL. It's designed to be a robust backend supporting cutting-edge features like AI-powered analytics, real-time payroll processing, blockchain integration, and advanced employee self-service.

## Features

- **High Performance:** Built with Rust and the Actix-web framework for speed and safety.
- **Asynchronous:** Fully async from the web layer down to the database.
- **Modern Database:** Uses PostgreSQL with `Diesel` for safe and efficient database interactions.
- **Advanced Data Models:** Supports complex JSON-based data structures for analytics, benefits, and more.
- **Ready for the Future:** Designed to integrate AI, blockchain, and real-time payment features.
- **Multi-Component Architecture:** Separate binaries for the web server, background worker, and scheduler for better separation of concerns and scalability.

## Architecture

The system is composed of three main components that run as separate processes:

- **Web Server (`basics`):** The main entry point for all API requests. It handles HTTP requests, validation, and calls the appropriate services.
- **Background Worker (`worker`):** Responsible for processing long-running, asynchronous tasks such as sending emails, generating reports, or processing payroll batches.
- **Scheduler (`scheduler`):** Manages and triggers scheduled tasks, such as running payroll on a specific date or generating monthly reports.

This separation allows for independent scaling and development of each component.

## Getting Started

### Prerequisites

- [Rust](https://www.rust-lang.org/tools/install) (latest stable version)
- [PostgreSQL](https://www.postgresql.org/download/)
- [Diesel CLI](https://diesel.rs/guides/getting-started) (`cargo install diesel_cli --no-default-features --features postgres`)
- [cargo-make](https://github.com/sagiegurari/cargo-make) (`cargo install cargo-make`)

### Installation & Running

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd <your-repo-folder>
    ```

2.  **Set up the environment:**
    Create a `.env` file in the project root and add your database URL:
    ```.env
    DATABASE_URL="postgres://user:password@localhost/your_db_name"
    ```

3.  **Run database migrations:**
    This will create and update your database tables to match the application's models.
    ```bash
    diesel migration run
    ```

4.  **Build and run the application:**
    The easiest way to get everything running for development is to use the `start-all` task, which will build and run the web server, worker, and scheduler in parallel.

    ```bash
    cargo make start-all
    ```

    The server will start on `http://127.0.0.1:8080`.

## Usage

This project uses `cargo-make` as a task runner to simplify common development tasks. The tasks are defined in the `Makefile.toml` file.

-   **`cargo make start-all`**: Builds and runs the web server, worker, and scheduler in parallel.
-   **`cargo make build-all`**: Compiles all binaries.
-   **`cargo make run-web`**: Runs the main web server binary.
-   **`cargo make run-worker`**: Runs the background worker binary.
-   **`cargo make run-scheduler`**: Runs the scheduler binary.

## API Documentation

The API is documented using the OpenAPI standard. You can access the interactive API documentation in two ways:

1.  **While the server is running:** Navigate to [http://127.0.0.1:8080/docs](http://127.0.0.1:8080/docs) in your browser.
2.  **Offline:** Open the `api-docs/scalar.html` or `api-docs/swagger.html` files directly in your browser.

The documentation provides a list of all available endpoints, their parameters, and response objects. You can also use the interactive interface to send test requests to the API.

## Testing

To run the test suite, use the following command:

```bash
cargo test
```

## Project Structure

```
.
├── api-docs/           # OpenAPI and Swagger documentation files
├── migrations/         # Diesel database migrations
├── src/
│   ├── api/            # API specific types and data structures
│   ├── bin/            # Entry points for the worker and scheduler binaries
│   ├── calculation/    # Business logic for payroll calculations
│   ├── config/         # Application configuration
│   ├── domain/         # Core domain models and error types
│   ├── services/       # Business logic services (e.g., PayrollService)
│   ├── web/            # Web handlers and routes
│   ├── db.rs           # Database connection setup
│   ├── lib.rs          # Library crate root
│   ├── main.rs         # Main web server entry point
│   └── schema.rs       # Auto-generated by Diesel
├── tests/              # Integration and unit tests
├── .env                # Environment variables (needs to be created)
├── Cargo.toml          # Project dependencies and metadata
└── Makefile.toml       # Task definitions for cargo-make
```

## Contributing

Contributions are welcome! Please feel free to submit a pull request.
